### About me ðŸ‘‹

ðŸŽ“ IT & AI Engineering - M.Eng at Polytechnique MontrÃ©al<br />
ðŸŽ“ Electrical Engineering - B.Eng at Ã‰cole de Technologie SupÃ©rieure <br />


## Projects

| Tag | Name | Description
|:---|:---|:---
|ML|[ðŸ”¥ Fire smoke detection](https://github.com/MorganPeju/inf8225_project) | Python - Forest fire smoke detection with YOLOv5 model

## Learning Journey

### [Computer Vision](https://github.com/khchu93/ComputerVision/tree/main)

#### Image Classification
- [GoogleNet](https://github.com/khchu93/ComputerVision/blob/main/notes/GoogLeNet.md), 2015 (keyword: Inception Module, GAP, Auxiliary Classifier, Multi-scales, 1 x 1 conv.)
- [ResNet](https://github.com/khchu93/ComputerVision/blob/main/notes/ResNet.md), 2015 (keyword: Residual Learning, Skip connection, GAP, bottleneck)
- [VGG](https://github.com/khchu93/ComputerVision/blob/main/notes/VGG.md), 2014 (keyword: very deep layers, very small convolutional filter 3 x 3)
- [AlexNet](https://github.com/khchu93/ComputerVision/blob/main/notes/AlexNet.md), 2012 (keyword: ReLU, Dropout)

#### Object Detection
- [Mask R-CNN](https://github.com/khchu93/ComputerVision/blob/main/notes/MaskedR-CNN.md), 2017 (keyword: RoIAlign, Mask Head, FPN, RPN, NMS)
- [Faster R-CNN](https://github.com/khchu93/ComputerVision/blob/main/notes/Faster%20R-CNN.md), 2015 (keyword: end-to-end, RPN, shared feature map, Fast R-CNN detector module)
- [Fast R-CNN](https://github.com/khchu93/ComputerVision/blob/main/notes/Fast%20R-CNN.md), 2015 (keyword: single stage, CNN only once, shared feature map, ROI pooling layer, 2 head FC layer output, NMS, region proposal)
- [R-CNN](https://github.com/khchu93/ComputerVision/blob/main/notes/R-CNN.md), 2014 (keyword: region proposal, selective search, Bounding box regression, NMS)
<!--
#### Semantic Segmentation
- U-Net, 2015 (TBD)

#### Real-time Detection
- YOLOv8, 2023 (TBD)
- YOLOv5, 2020 (TBD)
- YOLOv1, 2016 (TBD)

#### Multi-purpose
- DAMamba, 2024 (TBD)
- Vision Mamba, 2024 (TBD)
- Mamba, 2023 (TBD)
- ConvNeXt, 2022 (TBD)
- ViT(Vision Transformer), 2020 (TBD)

#### Multimodal
- SAM(Segment Anything Model), 2023 (TBD)
- CLIP, 2021 (TBD)
-->
### LLMs

#### Representation / Embeddings
- Seq2Seq, 2014 (TBD)
- Word2Vec, 2013 (TBD)

#### Foundational Architecture
- [Transformer](https://github.com/khchu93/LLMs/blob/main/notes/Transformer.md), 2017 (keyword: multi-head, self-attention, positional encoding, autoregression)
<!--
#### Understanding / NLP Pretraining
- T5, 2019 (TBD)
- BERT, 2018 (TBD)

#### Generation / Autoregressive Models
- GPT-2, 2019 (TBD)
- GPT, 2018 (TBD)

#### Instruction-Following / Alignment
- GPT-4, 2023 (TBD)
- InstructGPT, 2022 (TBD)
- GPT-3, 2020 (TBD)

#### Democratized / Frontier / Industrial-Scale Models
- DeepSeek, 2025 (TBD)
- LLaMA,2023 (TBD)
-->
